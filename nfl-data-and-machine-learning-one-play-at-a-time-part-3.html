<!doctype html>
<html lang="en" itemscope itemtype="http://schema.org/Person">
<head>
  <meta charset="utf-8">
  <!-- Site Meta Data -->
  <title>NFL Data and Machine Learning… One Play at a Time — Part 3</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="author" content="Michael Skrzypiec">

  <link rel="shortcut icon" href="/theme/images/icons/favicon.ico">

  <!-- schema.org -->
  <meta itemprop="name" content="Michael Skrzypiec">
  <meta itemprop="image" content="/theme/images/me_small.jpg">
  <meta itemprop="description" content="">

  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,600,700' rel='stylesheet' type='text/css'>
  <!-- Style Meta Data -->
  <link rel="stylesheet" href="/theme/css/style.css" type="text/css" />
  <link rel="stylesheet" href="/theme/css/pygments.css" type="text/css" />

  <!-- Feed Meta Data -->

  <!-- Twitter Feed -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="skrzym">
  <meta name="twitter:image" content="">

<meta name="twitter:creator" content="skrzym">
<meta name="twitter:url" content="/nfl-data-and-machine-learning-one-play-at-a-time-part-3.html">
<meta name="twitter:title" content="Michael Skrzypiec ~ NFL Data and Machine Learning… One Play at a Time — Part 3">
<meta name="twitter:description" content="Develop model one step further and incorporate some more advanced methods to indicate which actions on a play lead to positive or negative outcomes.">

<!-- Facebook Meta Data -->
<meta property="og:title" content="Michael Skrzypiec ~ NFL Data and Machine Learning… One Play at a Time — Part 3" />
<meta property="og:description" content="Develop model one step further and incorporate some more advanced methods to indicate which actions on a play lead to positive or negative outcomes." />
<meta property="og:image" content="" />
</head>

<body>
  <!-- Sidebar -->
  <aside>
    <center><a href=""><img id="avatar" src="/theme/images/me_small.jpg"></a></center>
    <h1>Michael Skrzypiec</h1>
      <p>Data Analyst/Project Manager</p>
    <br>

      <a class="twitter-follow-button"
      href="https://twitter.com/skrzym"
      data-show-count="false"
      data-lang="en">
      Follow @twitterdev
      </a>
      <script type="text/javascript">
      window.twttr = (function (d, s, id) {
        var t, js, fjs = d.getElementsByTagName(s)[0];
        if (d.getElementById(id)) return;
        js = d.createElement(s); js.id = id;
        js.src= "https://platform.twitter.com/widgets.js";
        fjs.parentNode.insertBefore(js, fjs);
        return window.twttr || (t = { _e: [], ready: function (f) { t._e.push(f) } });
      }(document, "script", "twitter-wjs"));
      </script>

    <nav class="nav">
      <ul class="list-bare">

          <li><a class="nav__link" href="/blog.html">Recent Posts</a></li>
          <li><a class="nav__link" href="/categories.html">Categories</a></li>
          <li><a class="nav__link" href="/tags.html">Tags</a></li>
          <li><a class="nav__link" href="/#aboutme">About Me</a></li>


      </ul>
    </nav>

    <p class="social">
        <a href="https://www.linkedin.com/in/michaelskrzypiec" target="_blank" ><img src="/theme/images/icons/linkedin.png"></a>
        <a href="https://github.com/skrzym" target="_blank" ><img src="/theme/images/icons/github.png"></a>
        <a href="https://twitter.com/skrzym" target="_blank" ><img src="/theme/images/icons/twitter.png"></a>
    </p>



  </aside>

  <!-- Content -->
  <article>
<section id="content">
    <article>
        <h2 class="post_title post_detail"><a href="/nfl-data-and-machine-learning-one-play-at-a-time-part-3.html" rel="bookmark" title="Permalink to NFL Data and Machine Learning… One Play at a Time — Part 3">NFL Data and Machine Learning… One Play at a Time — Part 3</a></h2>
        <div class="entry-content blog-post">
            <p><em>How to make our model better.</em></p>
<p><em>In our last post we got more technical about our data, made a basic model to
choose the right play given a specific game scenario, and showcased a web app
developed to run the model whenever, wherever you want.</em></p>
<p><em>Part one investigated our data-set provided by the NFL APIs since the 2009
season and explored it in different ways. We looked at few different
visualizations of the game and dug into how a rule change back in 2015 could be
detected in the data.</em></p>
<p><em>Here we will take this model one step further and incorporate some more
advanced methods to indicate which actions on a play lead to positive or
negative outcomes.</em></p>
<h3>What’s Really Important</h3>
<p>NFL play predictions are tough to get exactly right. We have already attempted
to solve this with a basic model with basic play details. However, the key
information anyone wants to know about a play is not only what play makes sense
for the current game situation, it is also how positive or negative the impact
of doing one type of play vs another is on the outcome of the game. We can
formulate this by incorporating our response variable from the first model(play
type) into this model, along with the offensive and defensive teams taking part
in the given play. We will use the same Random Forest Classifier machine
learning method with a new response variable we will compute from the data
available. This response variable we need to come up with is whether a play was
a “good” or “bad” idea.</p>
<p>Before we go further we need to discuss our scoring metric setup and dig a bit
deeper into some challenges we face with this machine learning problem. To
generate this new metric we have to look at the impact of a play on the game in
as general or specific of a way we like. A statistic that can give a good
indication of this is to look at the results of the overall drive of a play and
provide it a positive or negative connotation depending on the outcome of the
drive. If that drive resulted in scoring points then it would be a positive
outcome. The resulting “good” or “bad” nature of a play could also be determined
by other factors such as number of points earned for the drive or yards gained
on the play. Even severe penalties could be incorporated for fumbling and
throwing an interception.</p>
<p>So with all these options why are we going to proceed with a binary response
variable? (1 if points were scored on the drive and 0 if no points were scored)
Reliability. Machine learning methods have been developed for addressing this
ranking classification issue but each have various caveats and pitfalls that can
severely hamper our analysis. Our venture with this model will rely on the more
tested and understood binary response for supervised classification. If we see
promising results then it would be safe to assume further refinement of the
success metric and experimentation with these alternative machine learning
methods for ranked classification can be done with even stronger predictive
power when handled properly. We have to start somewhere though, so lets see what
comes of our original idea.</p>
<h3>Searching For Answers</h3>
<p>Our data set is pulled together using nflscrapR (with an R script described in
the previous post). It has information on what drive each play is a part of,
however, we want to know the ultimate result for each drive of a game. Did a
given play occur on a drive that ultimately gained points or turned it back over
to the other team?</p>
<p>To accomplish this we have two options. First we can go through all our existing
data and pull out the last play of each drive we have. That last play should
indicate if the drive was a success (Touchdown, Field Goal) or a failure (Punt,
Downs, Interception). We can also get this data through a python package named
<em>nflgame</em>. This packages lets us compile not only play-by-play data, but game
and drive specific data via python data structures. We will use the second
option here since it really is a toss up between the two and exploring another
API and incorporating new data into our existing data set will be a good
challenge.</p>
<div class="highlight"><pre><span></span>api_data = []
gid = None
did = None
dre = None
for season in seasons:
    for kind in kinds:
        print(season,kind,&#39;gathering...&#39;)
        games = nflgame.games(season, kind=kind)
        plays = nflgame.combine_plays(games)
        plist = [play for play in plays]
        for p in plist:
            game_id = p.drive.game.eid
            drive_id = p.drive.drive_num
            drive_res = p.drive.result
            if gid != game_id: gid = game_id
            if dre != drive_res: dre = drive_res
            if did != drive_id:
                did = drive_id
                api_data.append({&#39;gid&#39;:gid,&#39;did&#39;:did,&#39;dre&#39;:dre})
</pre></div>


<p>In the above code we are generating play data for every play available in the
regular and post seasons games. For each play we check if the drive is different
than the last one. If it is we take a snapshot of that play’s drive number, game
id, and of course the result of the drive. We store this as a dictionary in a
running list. Once we have gone through each of the plays we convert the list of
dictionaries to a pandas data frame though the use of the following function:</p>
<div class="highlight"><pre><span></span>pd.DataFrame.from_records()
</pre></div>


<p>This will take our list of dictionaries, extract each key to be a new column and
populate that column with the corresponding variable from each dictionary. Next
we store this as a csv file (why not, it took a long time to run) and get
started on integrating this data with our original data set.</p>
<p>The next step is to merge this new <code>drive_result</code> column with our old data set.
This process would have been a lot simpler if every play in the original data
was labeled with a playID, but of course the more complicated way is required.</p>
<div class="highlight"><pre><span></span>def mapper(row):
    df1 = ext.loc[ext.GameID == row.GameID]
    df2 = df1.loc[df1.Drive == row.Drive]
    if len(df2) == 1:
        return df2.drive_result.values[0]
    else:
        return None
</pre></div>


<p>This mapping function takes each row from our old dataset and manually joins
itself with our new drive information via GameID and Drive. If a match is found
we return the corresponding drive result.</p>
<p>Now we have added a column to our original data that states what the outcome of
the play’s drive will be. For our purposes this value needs to be converted from
its current categorical nature to that of a binary, good or bad, response
variable. This is the point in the analysis we had discussed before that could
change this problem from a binary classification to a ranked one if we so
desired.</p>
<h3>Dummies</h3>
<p>Now that all our key pieces of data are ready for analysis we should be able to
begin fitting our model and tuning results right? Not so fast! Since we are
using a scikit-learn’s <code>RandomForestClassifier()</code> we have to convert our
categorical input values to a whole lot of dummy ones using a process called<em>
<a href="https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science">one-hot
encoding</a></em> .
The basic premise is as follows: You have a categorical variable with three
different possible categories, yes, no, and maybe. One-hot encoding means you
need to replace that one column with three columns, each of which can only be 0
(cold) or 1 (hot). The names of these columns would match that of the different
levels in the original categorical variable. This is done to preserve a
categorical value’s information when trying to use it’s predictive power on a
tool that doesn’t play nicely with categories.</p>
<p>There are drawbacks to doing this though as in our case we need to convert our
two NFL team factors and our play type factor. This adds a substantial number of
columns to our input for our classifier. Though once complete we can begin
fitting and tuning our model.</p>
<h3>Performance</h3>
<p>After splitting the data for testing and training, we run a RandomizedSearchCV
to search the hyperparameter space for the optimum settings on our Random Forest
Classifier. Below you can see what was used as an input for the parameter space
that should be randomly searched by the cross validation / tuning function.</p>
<div class="highlight"><pre><span></span>param_dist = {&quot;max_depth&quot;: [3, None],
              &quot;max_features&quot;: sp_randint(1, 20),
              &quot;min_samples_split&quot;: sp_randint(2, 111),
              &quot;min_samples_leaf&quot;: sp_randint(1, 111),
              &quot;bootstrap&quot;: [True, False],
              &quot;criterion&quot;: [&quot;gini&quot;, &quot;entropy&quot;]}
</pre></div>


<p>After 10 K-folds on 10 different randomized parameter sets totaling 100
different fits of the model our best score came back as 0.77964. Not bad at all
given the increased complexity of this model vs our previous one. We
experimented with removing the current playing teams from the model to see how
impactful they were only to find our results would be barely better than
randomly guessing at 0.55. Keeping the team information definitely strengthens
our model.</p>
<p>Satisfied with our hyper parameter tuning results we fit the resulting best
parameters to a new classifier, fit it against our training data and tested it
on our test set to get a score of 0.781! It actually has improved on our test
data.</p>
<p>Lets take a look at the ROC curve.</p>
<p><img alt="ROC Curve" src="https://cdn-images-1.medium.com/max/1600/1*drOmjLda3Qg1QjMHP174pg.png" /></p>
<p>The two lines are just mirrors of one another. The key here is to understand
that a perfect model would have a curve that looks more like a right angle
passing through point (0,1). On the other hand, the closer our curve get’s to
passing through (0.5,0.5) the closer it is to just randomly guessing an answer.
This is typically reviewed by looking at the AUC or area under the curve which
is provided in the legend area of this chart. We have an AUC of 0.76. Much
better than random guessing but still failing in certain cases.</p>
<p>You can find this model in the GitHub repo for this project as well as on
<a href="http://34.212.37.176/">Monday Morning Quarterback </a>where you can put your own
input’s in and see what it thinks about your decision to have the Jets pass the
ball when down by 3 in the 4th with 10 yards to go when playing the Patriots.</p>
<p>Hope you enjoyed reading this!</p>
<hr />
<p><strong>Thanks for reading!</strong></p>
<p><strong>Feel free to reach out to me via the links below.</strong></p>
<p><a href="https://www.linkedin.com/in/michaelskrzypiec/">LinkedIn</a><strong> |
</strong><a href="https://twitter.com/Skrzym">Twitter</a><strong> | </strong><a href="https://github.com/skrzym">GitHub
</a><strong>| </strong><a href="http://www.michaelskrzypiec.com/">Website</a></p>
<p>**See this post on Medium <a href="https://medium.com/@skrzym/nfl-data-and-machine-learning-one-play-at-a-time-part-3-18ea1bc3e9fa">here</a></p>
        </div>
        <div class="post_list">
            <span>By </span>
            <a href="/author/michael-skrzypiec.html">@Michael Skrzypiec</a>
            <span> in </span>
            <span class="post_category"><a href="/category/data-science.html" rel="bookmark" title="Permalink to Data Science">[ Data Science ]</a></span>
            <span class="post_date">Mon 02 October 2017</span>
            <div><span>Tags : </span>
                <span><a href="/tag/nfl.html">#NFL, </a></span>
                <span><a href="/tag/python.html">#Python, </a></span>
                <span><a href="/tag/machine-learning.html">#Machine Learning, </a></span>
                <span><a href="/tag/random-forest.html">#Random Forest, </a></span>
                <span><a href="/tag/classification.html">#Classification, </a></span>
            </div>

            <div class="entry-social">
                <span class="twitter"><a target="_blank" rel="nofollow" onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=400,width=700');return false;" title="Twitter" href="https://twitter.com/share?url=/nfl-data-and-machine-learning-one-play-at-a-time-part-3.html&text=NFL Data and Machine Learning… One Play at a Time — Part 3&via=skrzym"><img src="/theme/images/icons/twitter-s.png"></a></span>

                <span class="gplus"><a target="_blank" title="Google +" href="https://plus.google.com/share?url=/nfl-data-and-machine-learning-one-play-at-a-time-part-3.html&hl=fr" rel="nofollow" onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=450,width=650');return false;"><img src="/theme/images/icons/google-s.png"></a></span>

                <span class="facebook"><a target="_blank" title="Facebook" rel="nofollow" onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=500,width=700');return false;" href="https://www.facebook.com/sharer.php?u=/nfl-data-and-machine-learning-one-play-at-a-time-part-3.html&t=NFL Data and Machine Learning… One Play at a Time — Part 3"><img src="/theme/images/icons/facebook-s.png"></a></span>

                <a  target="_blank" title="Linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=/nfl-data-and-machine-learning-one-play-at-a-time-part-3.html&title=NFL Data and Machine Learning… One Play at a Time — Part 3" rel="nofollow" onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=450,width=650');return false;"><img src="/theme/images/icons/linkedin-s.png"></a>

                <span class="mail"><a href="mailto:?subject=NFL Data and Machine Learning… One Play at a Time — Part 3&amp;body=Viens découvrir un article à propos de [NFL Data and Machine Learning… One Play at a Time — Part 3] sur le site de Michael Skrzypiec. /nfl-data-and-machine-learning-one-play-at-a-time-part-3.html" title="Share by Email" target="_blank"><img src="/theme/images/icons/mail-s.png"></a></span>
            </div>
        </div>
    </article>
</section>
<!-- JupyterStyleSheet -->
<link rel="stylesheet" href="/theme/css/ipynb.css" type="text/css" />
  </article>

  <!-- Footer -->
  <footer>
    <p>
      Blog powered by <a href="http://getpelican.com/">Pelican</a>,
      which takes great advantage of <a href="http://python.org">Python</a>.
      Theme <a href="https://github.com/parbhat/pelican-blue">Pelican-Blue</a> by <a href="https://parbhatpuri.com/">@parbhat</a>.
    </p>
  </footer>


</body>
</html>